{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a83f95c3",
   "metadata": {},
   "source": [
    "## Resume Analysis\n",
    "\n",
    "In this activity, you will generate a Python script to analyze a resume text file.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "* Read the resume file as text using the `with` statement.\n",
    "\n",
    "* Create a list containing all words in the resume.\n",
    "\n",
    "  * Convert each word to lowercase to normalize the data.\n",
    "\n",
    "* Use `split` to remove and trailing punctuation so only words remain.\n",
    "\n",
    "* Create a set of unique words from the resume using `set()`.\n",
    "\n",
    "* Use set operations to filter out all remaining punctuation from the set of words.\n",
    "\n",
    "  * Create a set from `string.punctuation` to use in the difference operation.\n",
    "\n",
    "* Use the cleaned set (no punctuation) to find all of the words from the resume that match the required skills.\n",
    "\n",
    "* Use the cleaned set (no punctuation) to find all of the words that match the desired skills."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "15412911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dependencies\n",
    "import os\n",
    "import string\n",
    "\n",
    "# a function that grabs the text from a resume file and calls a cleaner function to return a cleaned\n",
    "# list of words from the resume\n",
    "def LoadResume(resumefile=\"resume.md\"):\n",
    "    \n",
    "    filepath = os.path.join(\"ResumeHolder\", \"resume.md\")\n",
    "    \n",
    "    with open(filepath, 'r') as resume:\n",
    "        raw_text = resume.read()\n",
    "    \n",
    "    # split raw text by spaces \n",
    "    unprocessed_wordlist = raw_text.split()\n",
    "    \n",
    "    # call the cleaner function\n",
    "    processed_wordlist = CleanResume(unprocessed_wordlist)\n",
    "    \n",
    "    # return the cleaned list of resume words\n",
    "    return processed_wordlist\n",
    "\n",
    "\n",
    "# a function that takes in an unprocessed string of words and purges them of three common punctuation marks\n",
    "def CleanResume(dirty):\n",
    "    \n",
    "    # split by common punctuation marks and take the word portion of the output\n",
    "    clean = [word.lower().split(',')[0].split('.')[0].split('/')[0] \n",
    "             for word in dirty if word[0] in string.ascii_letters]\n",
    "        \n",
    "    return clean\n",
    "\n",
    "\n",
    "# define a function that takes in a cleaned list of resume words, required skills, and desired skills\n",
    "# and outputs matches and misses \n",
    "def MatchSkills(candidate_skills,\n",
    "                req_skills = {\"excel\", \"python\", \"mysql\", \"statistics\"},\n",
    "                des_skills = {\"r\", \"git\", \"html\", \"css\", \"leaflet\"}):\n",
    "    \n",
    "    candidate_skills = set(candidate_skills)\n",
    "    \n",
    "    matched_req = req_skills & candidate_skills\n",
    "    missing_req = req_skills - candidate_skills\n",
    "    \n",
    "    matched_des = des_skills & candidate_skills\n",
    "    missing_des = des_skills - candidate_skills\n",
    "    \n",
    "    print(f\"The candidate has the following required skils:  {list(matched_req)}.\\n\" +\n",
    "          f\"The candidate is missing the following required skills:  {list(missing_req)}.\\n\\n\" +\n",
    "          f\"The candidate has the following desired skils:  {list(matched_des)}.\\n\" + \n",
    "          f\"The candidate is missing the following desired skils:  {list(missing_des)}.\")\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d2ba216b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The candidate has the following required skils:  ['mysql', 'python', 'excel', 'statistics'].\n",
      "The candidate is missing the following required skills:  [].\n",
      "\n",
      "The candidate has the following desired skils:  ['css', 'r', 'git', 'html', 'leaflet'].\n",
      "The candidate is missing the following desired skils:  [].\n"
     ]
    }
   ],
   "source": [
    "# load the resume, recognizing that \n",
    "cur_resume = LoadResume()\n",
    "\n",
    "MatchSkills(cur_resume)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21cf4f10",
   "metadata": {},
   "source": [
    "#### Bonuses\n",
    "\n",
    "* Count the number of occurrences for each word in the resume and print the top 10 occuring words in the resume.\n",
    "\n",
    "  * Use a dictionary data structure to hold the counts for each word.\n",
    "\n",
    "  * Make sure to remove punctuation and [stop words](https://en.wikipedia.org/wiki/Stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "0e2b3702",
   "metadata": {},
   "outputs": [],
   "source": [
    "def WordCount(wordlist, \n",
    "              stop_words = {\"and\", \"with\", \"using\", \"##\", \"working\", \"in\", \"to\"},\n",
    "              top = False, n=10):\n",
    "    \n",
    "    # convert to a set and then back to a list to grab the unique values\n",
    "    unique_list = list(set(wordlist) - stop_words)\n",
    "    \n",
    "    # create a dictionary where keys are resume words and values are counts\n",
    "    # default count value is 0\n",
    "    wordcount = dict.fromkeys(unique_list, 0)\n",
    "    \n",
    "    # loop through word list and increase count for every encounter\n",
    "    for word in wordlist:\n",
    "        \n",
    "        if word in wordcount.keys():\n",
    "            wordcount[word] += 1\n",
    "        \n",
    "    # if th user specifies they want only the top n words, call a custom function\n",
    "    if top:\n",
    "        \n",
    "        topwords = TopWords(wordcount, n)\n",
    "        \n",
    "        return topwords\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        return wordcount\n",
    "\n",
    "# define a function that grabs the top n words from a wordcount dictionary\n",
    "def TopWords(wordcount, n):\n",
    "    \n",
    "    # sort the wordcount keys by value in descending order and cut the list off at n words\n",
    "    top = sorted(wordcount, key=wordcount.get, reverse=True)[:n]\n",
    "    \n",
    "    # reconstruct a dictionary by zipping the wordcount list with a corresponding frequency value list\n",
    "    top_dict = dict(zip(top, [wordcount[w] for w in top]))\n",
    "    \n",
    "    return top_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "17b4a375",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'stein': 1,\n",
       " 'the': 2,\n",
       " 'frank': 1,\n",
       " 'cloud': 1,\n",
       " 'apis': 1,\n",
       " 'hadoop': 2,\n",
       " 'developing': 1,\n",
       " 'designing': 1,\n",
       " 'social': 2,\n",
       " 'mysql': 1,\n",
       " 'experience': 1,\n",
       " 'intelligence': 1,\n",
       " 'visualizations': 1,\n",
       " 'python': 4,\n",
       " 'pandas': 1,\n",
       " 'statistics': 2,\n",
       " 'modeling': 1,\n",
       " 'aws': 1,\n",
       " 'tableau': 2,\n",
       " 'advanced': 1,\n",
       " 'javascript': 2,\n",
       " 'r': 1,\n",
       " 'creating': 1,\n",
       " 'excel': 2,\n",
       " 'education': 1,\n",
       " 'boot': 1,\n",
       " 'd3': 2,\n",
       " 'vba': 1,\n",
       " 'front-end': 1,\n",
       " 'mongodb': 1,\n",
       " 'forecasting': 1,\n",
       " 'microsoft': 1,\n",
       " 'open-source': 1,\n",
       " 'performing': 1,\n",
       " 'git': 1,\n",
       " 'learning': 2,\n",
       " 'html': 3,\n",
       " 'n': 1,\n",
       " 'writing': 1,\n",
       " 'interests': 1,\n",
       " 'css': 2,\n",
       " 'skills': 1,\n",
       " 'databases': 1,\n",
       " 'bootstrap': 1,\n",
       " 'web': 2,\n",
       " 'data': 7,\n",
       " 'analytics': 3,\n",
       " 'algorithms': 1,\n",
       " 'contributing': 1,\n",
       " 'software': 2,\n",
       " 'api': 1,\n",
       " 'scripts': 2,\n",
       " 'machine': 2,\n",
       " 'graduate': 1,\n",
       " 'tables': 1,\n",
       " 'mining': 2,\n",
       " 'sets': 1,\n",
       " 'big': 2,\n",
       " 'media': 2,\n",
       " 'leaflet': 1,\n",
       " 'files': 1,\n",
       " 'analyze': 1,\n",
       " 'sql': 1,\n",
       " 'visualization': 2,\n",
       " 'pivot': 1,\n",
       " 'business': 1,\n",
       " 'interactions': 1,\n",
       " 'basic': 1,\n",
       " 'from': 1,\n",
       " 'apps': 1,\n",
       " 'camp': 1}"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WordCount(cur_resume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "69430e05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': 7,\n",
       " 'python': 4,\n",
       " 'html': 3,\n",
       " 'analytics': 3,\n",
       " 'the': 2,\n",
       " 'hadoop': 2,\n",
       " 'social': 2,\n",
       " 'statistics': 2,\n",
       " 'tableau': 2,\n",
       " 'javascript': 2,\n",
       " 'excel': 2,\n",
       " 'd3': 2,\n",
       " 'learning': 2,\n",
       " 'css': 2,\n",
       " 'web': 2}"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WordCount(cur_resume, top=True, n=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "7177c14e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': 7,\n",
       " 'python': 4,\n",
       " 'html': 3,\n",
       " 'analytics': 3,\n",
       " 'the': 2,\n",
       " 'hadoop': 2,\n",
       " 'social': 2,\n",
       " 'statistics': 2,\n",
       " 'tableau': 2,\n",
       " 'javascript': 2}"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WordCount(cur_resume, top=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc05966",
   "metadata": {},
   "source": [
    "#### Hints\n",
    "\n",
    "* Carefully consider when to use a Dictionary data structure vs. a Set data structure when operating on Unique and Non-unique elements."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
